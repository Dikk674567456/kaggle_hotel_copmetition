{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":34288,"databundleVersionId":3207826,"sourceType":"competition"}],"dockerImageVersionId":30157,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# импортируем библиотеки для визуализации\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\n\n# Загружаем специальный удобный инструмент для разделения датасета:\nfrom sklearn.model_selection import train_test_split\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 42","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Подгрузим наши данные из соревнования\n\nDATA_DIR = '/kaggle/input/sf-booking/'\ndf_train = pd.read_csv(DATA_DIR+'/hotels_train.csv') # датасет для обучения\ndf_test = pd.read_csv(DATA_DIR+'hotels_test.csv') # датасет для предсказания\nsample_submission = pd.read_csv(DATA_DIR+'/submission.csv') # самбмишн","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.head(2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_test.head(2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_submission.head(2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_submission.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['reviewer_score'] = 0 # в тесте у нас нет значения reviewer_score, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndata = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Очистка** ","metadata":{}},{"cell_type":"code","source":"# Выделим из всего датасета \"data\" наименования отелей, где есть пропуски координат.\ndata[data['lat'].isnull()]['hotel_name'].value_counts()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Составим словарь наименований отеля и их координат\ncoord_dict = {\n    'Fleming s Selection Hotel Wien City':[48.209095, 16.354568],\n    'Hotel City Central':[48.213560, 16.379923],\n    'Hotel Atlanta':[48.220310, 16.355880],\n    'Maison Albar Hotel Paris Op ra Diamond':[48.875140, 2.323420],\n    'Hotel Daniel Vienna':[48.188835, 16.383810],\n    'Hotel Pension Baron am Schottentor':[48.216705, 16.359820],\n    'Austria Trend Hotel Schloss Wilhelminenberg Wien':[48.219555, 16.285566],\n    'NH Collection Barcelona Podium':[41.391430, 2.177890],\n    'Derag Livinghotel Kaiser Franz Joseph Vienna':[48.245914, 16.341188],\n    'City Hotel Deutschmeister':[48.220856, 16.366642],\n    'Holiday Inn Paris Montmartre':[48.888860, 2.333190],\n    'Hotel Park Villa':[48.233495, 16.345556],\n    'Cordial Theaterhotel Wien':[48.209530, 16.351515],\n    'Roomz Vienna':[48.22201, 16.39331],\n    'Mercure Paris Gare Montparnasse':[48.839701, 2.323519],\n    'Hotel Advance':[41.38322, 2.16295],\n    'Renaissance Barcelona Hotel':[41.392430, 2.167500]\n}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Заполним пропуски в датасете\ndef fill_coords(row):\n    if pd.isna(row.lat):\n        coord = coord_dict[row.hotel_name]\n        if coord is not None:\n            row.lat = coord[0]\n            row.lng = coord[1]\n            return row\n    else:\n        return row\n\ndata = data.apply(lambda row: fill_coords(row), axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Проверим результаты преобразований\ndata.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Преобразование признаков, создание новых**","metadata":{}},{"cell_type":"code","source":"# Преобразование признака - Количество дней с отзыва\ndata['days_since_review']=data['days_since_review'].apply(lambda x: int(x.replace(' days', '').replace(' day', '')))\n\n# Создаем новые признаки из даты отзыва\n\ndata['year']=pd.to_datetime(data['review_date']).dt.year\ndata['month']=pd.to_datetime(data['review_date']).dt.month\ndata['day']=pd.to_datetime(data['review_date']).dt.day\ndata['season']=data['month'].apply(lambda x: \n                                                   'winter' if x in [12,1,2] else \n                                                   ('spring' if x in [3,4,5] else \n                                                    ('summer' if x in [6,7,8] else \n                                                     'fall' )))\n\ndata=pd.get_dummies(data, columns=['season'], drop_first=True)\n","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Вывод** - был преобразован в числовой признак days_since_review и созданы новые признаки year, month, days, и семейство season","metadata":{}},{"cell_type":"markdown","source":"# **Визуализации, распределения, корреляции**","metadata":{}},{"cell_type":"code","source":"\nsns.pairplot(data, y_vars=['reviewer_score'], diag_kind='hist')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Одна строка для построения всех гистограмм числовых столбцов\ndata.hist(figsize=(15, 10), bins=30, edgecolor='black')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nimport statsmodels.api as sm\nfrom sklearn import datasets\nfrom matplotlib import pyplot as plt\n\n# загружаем данные\n\n\n# задаём параметры квантиль-квантиль графика\nsm.qqplot(data['average_score'], line='s')\nplt.title('Квантиль-квантиль график \\n распределения average_score')\n\n# отображаем квантиль-квантиль график\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n#data=data.drop(['year'], axis=1)\n#data=data.drop(['additional_number_of_scoring'], axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Вывод** - целевая переменная reviewer_score не распределена ни нормально, ни логонормально. Распределение, похожее на нормальное, есть только у average_score, но судя по Квантиль-квантиль графику таковым не является.<br>\n  \nДиаграммы рассеяния позволяют сделать вывод о возможной кореляции  с reviewer_score признаков total_number_of_reviews_reviewer_has_given и review_total_positive_word_counts<br><br>\n","metadata":{}},{"cell_type":"markdown","source":"# **Создание новых признаков** ","metadata":{}},{"cell_type":"code","source":"\n# Разбираем Tags\n\npd.set_option('display.max_colwidth', None)\npd.set_option('display.max_rows', None)\ndata['tags'].sample(10)\ndata['hotel_address'].sample(10)\n\n# Новый признак - Количество тегов в отзыве\n\ndata['tags'] = data['tags'].apply(lambda x: x[3:-3].split(\" ', ' \"))\n\ndata['num_tags']=data['tags'].apply(lambda x: len(x))\n\n\n# Функция, которая возвращает тег с заданным ключевым словом\ndef tags(string_tags):\n    for i in string_tags:\n        if goal_tag in i:\n            return i\n    return None\n\n# Функция, которая возвращает 1-0\ndef tags_1_0(string_tags):\n    for i in string_tags:\n        if goal_tag in i:\n            return 1\n    return 0\n\n# Функция, которая возвращает тег с одиним из ключевых слов, обохзначающих кол-во гостей\ndef num_guests(string_tags):\n    for i in string_tags:\n        if 'Group' in i or 'Couple' in i or 'Solo' in i or 'young children' in i or 'older children' in i:\n            return i\n    return None\n    \n# Новый признак - Тип путешествия\ngoal_tag='trip'\ndata['sort_trip']=data['tags'].apply(tags)\nmy_mode=data['sort_trip'].mode()[0]\ndata['sort_trip']=data['sort_trip'].fillna(my_mode)\ndata['sort_trip']=data['sort_trip'].apply(lambda x: 1 if x=='Leisure trip' else 0)\n\n\n# Новый признак - Количество ночей\ngoal_tag='night'\ndata['nights']=data['tags'].apply(tags)\ndata['nights']=data['nights'].str.replace(r'[^0-9]', '', regex=True)\ndata['nights']=pd.to_numeric(data['nights'], errors='coerce')\nmy_median=data['nights'].median()\ndata['nights']=data['nights'].fillna(my_median)\n\n\n# Новый признак - Отправка отзыва с телефона\ngoal_tag='Submitted from a mobile device'\ndata['mobile_review']=data['tags'].apply(tags_1_0)\n\n\n# Количество гостей\ndata['num_guests']=data['tags'].apply(num_guests)\n\n\n# Проверка\ndisplay(data['sort_trip'].value_counts())\ndisplay(data['nights'].value_counts())\ndisplay(data['mobile_review'].value_counts())\ndisplay(data['num_guests'].value_counts())\n\n\ndata = pd.get_dummies(data, columns=['num_guests'], drop_first=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Разбираем negative_review и positive_review\n\n\ndata['positive_char_count']=data['positive_review'].str.len()\ndata['negative_char_count']=data['negative_review'].str.len()\n\ndisplay(data['positive_char_count'].head(5))\ndisplay(data['negative_char_count'].head(5))\n\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nanalyzer = SentimentIntensityAnalyzer()\n\ndata['pos_sentiment']=data['positive_review'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\ndata['neg_sentiment']=data['negative_review'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n\ndisplay(data['pos_sentiment'].head())\ndisplay(data['neg_sentiment'].head())\n\n# подсчитывает количество заглавных букв в тексте (на случай если кто-то злой капслоком писал)\ndef count_uppercase_letters(text):\n   \n    if not isinstance(text, str):\n        return 0 # Возвращаем 0, если входное значение не является строкой (например, NaN)\n\n    count = 0\n    for char in text:\n        if char.isupper(): # Проверяем, является ли символ заглавной буквой\n            count += 1\n            \n    return round(count/len(text),4)\n\ndata['neg_big_chairs_per']=data['negative_review'].apply(count_uppercase_letters)\ndata['pos_big_chairs_per']=data['positive_review'].apply(count_uppercase_letters)\n\ndisplay(data['neg_big_chairs_per'].head())\ndisplay(data['pos_big_chairs_per'].head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display(data.info())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.set_option('display.max_colwidth', None)\npd.set_option('display.max_rows', None)\ndata['hotel_address'].sample(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Создаем новые признаки на основе reviewer_nationality\n\n# Обрезаем мусорные пробелы в начале и конце\ndata['reviewer_nationality']= data['reviewer_nationality'].str.strip()\nvalue_country=data['reviewer_nationality'].value_counts(normalize=True)\n\n# Создадим еще одну категорию - совпадаение страны отеля и гостя\ncountry_list=value_country.index\n\ndef get_country_from_adress(adress):\n\n    for i in country_list:\n        if i in adress:\n            return i\n    return 'Other'\n\n\ndata['hotel_country']=data['hotel_address'].apply(get_country_from_adress)\ndata['hotel_reviewer_country_equal']=(data['hotel_country']==data['reviewer_nationality'])\ndata['hotel_reviewer_country_equal']=data['hotel_reviewer_country_equal'].apply(lambda x: 1 if x==True else 0)\ndisplay(data['hotel_reviewer_country_equal'].value_counts())\n\n# Создаем новые катерогии через One Hot кодироваие\ndata = pd.get_dummies(data, columns=['hotel_country'], drop_first=True)\n\n# через двоичное кодирование\nimport category_encoders as ce # импорт для работы с кодировщиком\nbin_encoder = ce.BinaryEncoder(cols=['reviewer_nationality']) # указываем столбец для кодирования\ndata = bin_encoder.fit_transform(data)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Создаем новые признаки на основе hotel_address\ndata['hotel_address'].sample(20)\n\ndef extract_city(hotel_address):\n    if 'London' not in hotel_address:\n        parts = hotel_address.split(' ')\n        # Предполагаем, что город - последний элемент перед страной\n        city = parts[-2].strip()  \n        return city\n    return 'London'\n\n# Применяем функцию к каждому адресу\ndata['city'] = data['hotel_address'].apply(extract_city)\n\ndata['city'].value_counts()\n\ndata=pd.get_dummies(data, columns=['city'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Вывод** - создали несколько новых числовых признаков из текстовых признаков - negative_review, positive_review, tags,  hotel_address ","metadata":{}},{"cell_type":"markdown","source":"# **Мультиколлинераность**","metadata":{}},{"cell_type":"code","source":"\n# Числовые признаки\nnum_cols =[\n    'additional_number_of_scoring',\n    'average_score',\n    'review_total_negative_word_counts',\n    'total_number_of_reviews',\n    'review_total_positive_word_counts',\n    'total_number_of_reviews_reviewer_has_given',\n    'days_since_review',\n    'lat',\n    'lng',\n    'year',\n    'month',\n    'day',\n    'num_tags',\n    'nights',\n    'positive_char_count',\n    'negative_char_count',\n    'pos_sentiment',\n    'neg_sentiment',\n    'neg_big_chairs_per',\n    'pos_big_chairs_per'\n]\n\nplt.rcParams['figure.figsize'] = (15,10)\n\n# # так как признаки не нормально распределены, то метод Пирсона отпадает. \nsns.heatmap( data[num_cols].corr(method='spearman'), annot=True, fmt=\".2f\", cmap='coolwarm')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Категориальные признаки\ncat_cols=[\n    'reviewer_nationality_0',\n    'reviewer_nationality_1',\n    'reviewer_nationality_2',\n    'reviewer_nationality_3',\n    'reviewer_nationality_4',\n    'reviewer_nationality_5',\n    'reviewer_nationality_6',\n    'reviewer_nationality_7',\n    'season_spring',\n    'season_summer',\n    'season_winter',\n    'sort_trip',\n    'mobile_review',\n    'hotel_reviewer_country_equal',\n    'hotel_country_France',\n    'hotel_country_Italy',\n    'hotel_country_Netherlands',\n    'hotel_country_Spain',\n    'hotel_country_United Kingdom',\n    'city_Amsterdam',\n    'city_Barcelona',\n    'city_London',\n    'city_Milan',\n    'city_Paris',\n    'city_Vienna',\n     'num_guests_Family with older children',\n    'num_guests_Family with young children',\n    'num_guests_Group',\n    'num_guests_Solo traveler'\n]\n\n\nplt.rcParams['figure.figsize'] = (20,15)\n\n\nsns.heatmap(data[cat_cols].corr(method='kendall'), annot=True, fmt=\".2f\", cmap='coolwarm')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Удаляем все признаки с кореляцией больше 0.7 (один из пары)\n\n# List of columns to drop\ncolumns_to_drop = [\n    'neg_big_chairs_per',\n    'year',\n    'additional_number_of_scoring',\n    'hotel_country_France',\n    'hotel_country_Italy',\n    'hotel_country_Netherlands',\n    'hotel_country_Spain',\n    'hotel_country_United Kingdom',\n    'pos_sentiment',\n    'negative_char_count',\n    #'positive_char_count'\n]\n\n\ndata.drop(columns=columns_to_drop, axis=1, inplace=True)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Числовые признаки\nnum_cols =list(set(num_cols)-set(columns_to_drop))\n\nplt.rcParams['figure.figsize'] = (15,10)\n\n# # так как признаки не нормально распределены, то метод Пирсона отпадает. \nsns.heatmap( data[num_cols].corr(method='spearman'), annot=True, fmt=\".2f\", cmap='coolwarm')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_cols =list(set(cat_cols)-set(columns_to_drop))\n\nplt.rcParams['figure.figsize'] = (20,15)\n\n\nsns.heatmap(data[cat_cols].corr(method='kendall'), annot=True, fmt=\".2f\", cmap='coolwarm')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Вывод**   - тепловые карты показывают о мультиколлинеарности ряда признаков. Там где корреляция больще 0.7 - эти признаки я удалил\n","metadata":{}},{"cell_type":"code","source":"# убираем признаки которые еще не успели обработать, \n# модель на признаках с dtypes \"object\" обучаться не будет, просто выберем их и удалим\nobject_columns = data.select_dtypes(include='object').columns\ndata.drop(columns=object_columns, inplace=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Реализация обучения модели**","metadata":{}},{"cell_type":"code","source":"# Теперь выделим тестовую часть\ntrain_data = data.query('sample == 1').drop(['sample'], axis=1)\ntest_data = data.query('sample == 0').drop(['sample'], axis=1)\n\ny = train_data.reviewer_score.values            # наш таргет\nX = train_data.drop(['reviewer_score'], axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Проверка значимости признаков**","metadata":{}},{"cell_type":"code","source":"# Значимость категориальных признаков  хи-квадрат\n\ny=y.astype('int')\n\n\nfrom sklearn.feature_selection import chi2 # хи-квадрат\n\nimp_cat = pd.Series(chi2(X[cat_cols], y)[0], index=cat_cols)\nimp_cat.sort_values(inplace = True)\nimp_cat.plot(kind = 'barh')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Значимость для непрерывных признаков — тест ANOVA\n\nfrom sklearn.feature_selection import f_classif # anova\n\n\nimp_num = pd.Series(f_classif(X[num_cols], y)[0], index = num_cols)\nimp_num.sort_values(inplace = True)\nimp_num.plot(kind = 'barh')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Вывод** - мы видим более и менее значимые признаки. Но так как общее количество признаков невелико, то решил их не удалять.\nПодтвердилась выдвинутая ранее гипотеза о связи целевого признака с признаками total_number_of_reviews_reviewer_has_given и review_total_positive_word_counts","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n# выделим 20% данных на валидацию (параметр test_size)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# проверяем\ntest_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Импортируем необходимые библиотеки:\nfrom sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\nfrom sklearn import metrics # инструменты для оценки точности модели","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\nmodel = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Обучаем модель на тестовом наборе данных\nmodel.fit(X_train, y_train)\n\n# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n# Предсказанные значения записываем в переменную y_pred\ny_pred = model.predict(X_test)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def mean_absolute_percentage_error(y_true, y_pred):\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n    \n# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))\nprint('MAPE:', mean_absolute_percentage_error (y_test, y_pred))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\nplt.rcParams['figure.figsize'] = (10,10)\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(20).plot(kind='barh')","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Вывод** - оценка важности признаков по разным методикам не совпадает","metadata":{}},{"cell_type":"code","source":"test_data.sample(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_data = test_data.drop(['reviewer_score'], axis=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_submission","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict_submission = model.predict(test_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\npredict_submission","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"list(sample_submission)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sample_submission['reviewer_score'] = predict_submission\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Общий вывод по проекту**\n\nРабота в рамках проекта позволила улучшить метрику проекта MAPE.\n\nБыли проведены следующие манипуляции:\n\nУдаление строковых значений\nОчистка от пропущенных значений;\nСоздание новых признаков\nПреобразование признаков\nОтбор признаков\n","metadata":{}}]}